{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QIwTcxqN78ne"
   },
   "source": [
    "# Algorithmic Market Efficiency - Data Preparation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ga31qcQ478nh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firm-level factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firm-level factors from Gu et al. (2019)\n",
    "\n",
    "df_factors = pd.read_csv('data/factors.csv')\n",
    "\n",
    "df_factors.columns = map(str.lower, df_factors.columns)\n",
    "\n",
    "df_factors = df_factors.drop(columns='sic2')\n",
    "\n",
    "print(df_factors.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRSP database (retrieved Oct. 2019) : dropping of duplicates, computation of market capitalization\n",
    "\n",
    "df_crsp = pd.read_csv('data/crsp.csv')\n",
    "\n",
    "df_crsp = df_crsp.drop_duplicates(subset=['date', 'permno'])\n",
    "\n",
    "df_crsp['shrout'] = df_crsp['shrout'] * 1000 #shrout is in 1000s\n",
    "df_crsp['mktcap'] = df_crsp['shrout'] * abs(df_crsp['prc'])\n",
    "\n",
    "df_crsp = df_crsp[['permno', 'date', 'ret', 'mktcap', 'shrout']]\n",
    "\n",
    "print(df_crsp.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First merge that forms df, with df_factors as a basis\n",
    "\n",
    "df = pd.merge(df_factors, df_crsp, on=['permno', 'date'], how='left', validate='one_to_one')\n",
    "\n",
    "df['yyyymm'] = (df['date'] / 100).astype(int)\n",
    "\n",
    "df_factors = None\n",
    "df_crsp = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fama-French and Carhat factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fama-French aggregate factors, retrieved in Oct. 2019\n",
    "\n",
    "df_ff = pd.read_csv('data/ff.csv', header=2, skipfooter=96, engine='python')\n",
    "\n",
    "df_ff = df_ff.rename(columns={\"Unnamed: 0\": \"yyyymm\", \"Mkt-RF\": \"mkt_rf\"})\n",
    "df_ff.columns = map(str.lower, df_ff.columns)\n",
    "\n",
    "df_ff['rf'] = df_ff['rf'] / 100\n",
    "df_ff['mkt_rf'] = df_ff['mkt_rf'] / 100\n",
    "df_ff['smb'] = df_ff['smb'] / 100\n",
    "df_ff['hml'] = df_ff['hml'] / 100\n",
    "\n",
    "# Fama-French 5-factor variables, retrieved in May 2020\n",
    "\n",
    "df_ff5 = pd.read_csv('data/ff5.csv', header=2, skipfooter=60, engine='python')\n",
    "\n",
    "df_ff5 = df_ff5.rename(columns={\"Unnamed: 0\": \"yyyymm\", \"Mkt-RF\": \"mkt_rf\"})\n",
    "df_ff5.columns = map(str.lower, df_ff5.columns)\n",
    "\n",
    "df_ff5['rmw'] = df_ff5['rmw'] / 100\n",
    "df_ff5['cma'] = df_ff5['cma'] / 100\n",
    "\n",
    "# Momentum factor, retrieved in May 2020\n",
    "\n",
    "df_mom = pd.read_csv('data/mom.csv', header=11, skipfooter=98, engine='python')\n",
    "\n",
    "df_mom = df_mom.rename(columns={\"Unnamed: 0\": \"yyyymm\", \"Mom   \": \"mom\"})\n",
    "\n",
    "df_mom['mom'] = df_mom['mom'] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge factor databases together, backfill rmw and cma for the 4 missing years :\n",
    "\n",
    "df_ff = pd.merge(df_ff, df_ff5[['yyyymm','rmw','cma']], on=['yyyymm'], how='left', validate='many_to_one')\n",
    "\n",
    "df_ff = pd.merge(df_ff, df_mom[['yyyymm','mom']], on=['yyyymm'], how='left', validate='many_to_one')\n",
    "\n",
    "df_ff = df_ff.fillna(method='backfill')\n",
    "\n",
    "print(df_ff.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge onto df:\n",
    "\n",
    "df = pd.merge(df, df_ff, on=['yyyymm'], how='left', validate='many_to_one')\n",
    "\n",
    "df_ff = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macroeconomic predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macroeconomic predictors from Amit Goyalâ€™s website, retrieved in Nov. 2019\n",
    "\n",
    "df_macropredictors = pd.read_csv('data/macropredictors.csv', sep=';')\n",
    "\n",
    "df_macropredictors = df_macropredictors.drop(columns=['Index', 'csp'])\n",
    "\n",
    "df_macropredictors.columns = map(str.lower, df_macropredictors.columns)\n",
    "\n",
    "print(df_macropredictors.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge onto df:\n",
    "\n",
    "df = pd.merge(df, df_macropredictors, on=['yyyymm'], how='left', validate='many_to_one')\n",
    "\n",
    "df_macropredictors = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compustat Supplemental Short Interest File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compustat Supplemental Short Interest File, retrieved Feb. 2020\n",
    "\n",
    "df_shortinterest = pd.read_csv('data/shortinterest.csv')\n",
    "\n",
    "df_shortinterest = df_shortinterest.sort_values(by=['gvkey', 'iid', 'datadate', 'splitadjdate'])\n",
    "df_shortinterest = df_shortinterest.drop_duplicates(subset=['gvkey', 'iid', 'splitadjdate'], keep='last')\n",
    "\n",
    "df_shortinterest = df_shortinterest[['gvkey', 'iid', 'splitadjdate', 'shortintadj']]\n",
    "df_shortinterest = df_shortinterest.rename(columns={\"splitadjdate\": \"date\", \"shortintadj\": \"shortint\"})\n",
    "\n",
    "#Shift observations from end of previous month to beginning of current month\n",
    "df_shortinterest['shortint'] = df_shortinterest['shortint'].shift(periods=1)\n",
    "df_shortinterest = df_shortinterest.dropna(subset=['shortint'])\n",
    "\n",
    "print(df_shortinterest.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRSP / Compustat Merged Security Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRSP / Compustat Merged Security Monthly, retrieved Feb. 2020 : drop Nan permnos, \n",
    "# only keep Common Shares Outstanding and Monthly Trading Volume\n",
    "\n",
    "df_securitymonthly = pd.read_csv('data/securitymonthly.csv')\n",
    "\n",
    "df_securitymonthly.columns = map(str.lower, df_securitymonthly.columns)\n",
    "df_securitymonthly = df_securitymonthly.rename(columns={\"datadate\": \"date\", \"lpermno\": \"permno\"})\n",
    "\n",
    "df_securitymonthly = df_securitymonthly.dropna(axis='rows', subset=['permno'])\n",
    "df_securitymonthly = df_securitymonthly[['gvkey', 'iid', 'permno', 'date', 'cshtrm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Short Interest File onto Security Monthly using gvkey, iid, date and sic: should be one-to-one, but sadly isnt...\n",
    "# Collapse rows that are undiscernable in df by summing them first for each variable: dropping nas for each variable\n",
    "# first allows us to keep missing observations while summing over groups of observations that have missing values and\n",
    "# treating these as zeros; then compute short interest ratio (short interest over common shares outsanding)\n",
    "# and trading volume ratio (monthly trading volume over common shares outstanding) -> It would be better to\n",
    "# compute ratios first and then aggregate using weighed averages, but this is not possible with the available data...\n",
    "\n",
    "df_securitymonthly = pd.merge(df_securitymonthly, df_shortinterest, on=['gvkey', 'iid', 'date'], how='left', validate='many_to_one')\n",
    "\n",
    "df_securitymonthly_shortint = df_securitymonthly[['permno', 'date', 'shortint']]\n",
    "df_securitymonthly_shortint = df_securitymonthly_shortint.dropna(axis='rows', subset=['shortint'])\n",
    "df_securitymonthly_shortint = df_securitymonthly_shortint.groupby(['permno', 'date']).sum().reset_index()\n",
    "\n",
    "df_securitymonthly_cshtrm = df_securitymonthly[['permno', 'date', 'cshtrm']]\n",
    "df_securitymonthly_cshtrm = df_securitymonthly_cshtrm.dropna(axis='rows', subset=['cshtrm'])\n",
    "df_securitymonthly_cshtrm = df_securitymonthly_cshtrm.groupby(['permno', 'date']).sum().reset_index()\n",
    "\n",
    "df_securitymonthly = df_securitymonthly[['permno', 'date']]\n",
    "df_securitymonthly = df_securitymonthly.drop_duplicates(subset=['permno', 'date'], keep='first')\n",
    "\n",
    "df_securitymonthly = pd.merge(df_securitymonthly, df_securitymonthly_shortint, on=['permno', 'date'], how='left', validate='many_to_one')\n",
    "df_securitymonthly = pd.merge(df_securitymonthly, df_securitymonthly_cshtrm, on=['permno', 'date'], how='left', validate='many_to_one')\n",
    "\n",
    "print(df_securitymonthly.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final dataframe merge, cleaning and sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final merge onto df:\n",
    "\n",
    "df = pd.merge(df, df_securitymonthly, on=['permno', 'date'], how='left', validate='many_to_one')\n",
    "\n",
    "df_securitymonthly = None\n",
    "df_shortinterest = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unneeded variables, deleting observations with missing date, permno or return\n",
    "\n",
    "df = df.drop(columns=['yyyymm'])\n",
    "\n",
    "df['ret'] = pd.to_numeric(df['ret'], errors='coerce')\n",
    "\n",
    "df = df.dropna(axis='rows', subset=['date', 'permno', 'ret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing observations before 1958 (we do not have 1957 in full)\n",
    "\n",
    "df = df[df['date']>=19580131]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_D7sJ_xwBcd-",
    "outputId": "8deafab4-add7-47a4-ab75-241e417778ec"
   },
   "outputs": [],
   "source": [
    "# Sorting columns alphabetically, sorting rows by date and permno\n",
    "\n",
    "df = df[['date','permno','ret'] + sorted(list(set(df.columns) - set(['date','permno','ret'])))]\n",
    "\n",
    "df = df.sort_values(by=['date','permno'])\n",
    "\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vR1tXhqEBceB",
    "outputId": "849eaba7-88fe-4c93-9d49-9d2579ee9370"
   },
   "outputs": [],
   "source": [
    "dates = np.unique(df['date'].to_numpy())\n",
    "\n",
    "dtdates = pd.to_datetime(dates, format='%Y%m%d')\n",
    "\n",
    "permnos = np.unique(df['permno'].to_numpy())\n",
    "\n",
    "vrs = np.setdiff1d(np.array(df.columns), ['date','permno'])\n",
    "\n",
    "facs = np.setdiff1d(vrs, ['ret','shrout','cshtrm','shortint'])\n",
    "\n",
    "T, N, V, F = len(dates), len(permnos), len(vrs), len(facs)\n",
    "\n",
    "returns = df[['date','permno','ret',]].pivot(index='date', columns='permno', values='ret')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating df_ml and df_mktvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = df.drop(columns=['shrout','cshtrm','shortint'])\n",
    "\n",
    "df_ml = pd.DataFrame(scale(df_ml, axis=0), index=df_ml.index,columns=df_ml.columns)\n",
    "\n",
    "df_ml[['date', 'permno', 'ret']] = df[['date', 'permno', 'ret']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mktvars = df[['date', 'permno', 'ret', 'mktcap', 'shrout','cshtrm','shortint']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46qJHLbIBn1P"
   },
   "source": [
    "## Macro / market time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macrofacs = ['mkt_rf', 'smb', 'hml', 'rmw', 'cma', 'mom', 'rf', 'd12', 'e12',\n",
    "             'bm', 'tbl', 'aaa', 'baa', 'lty', 'ntis', 'rfree', 'infl', \n",
    "             'ltr', 'corpr', 'svar', 'crsp_spvw', 'crsp_spvwx']\n",
    "\n",
    "macrodf = df.loc[:,macrofacs + ['date']]\n",
    "macrodf = macrodf.drop_duplicates(subset='date')\n",
    "macrodf = macrodf.set_index('date')\n",
    "\n",
    "rf = macrodf['rf']\n",
    "mkt_rf = macrodf['mkt_rf']\n",
    "smb = macrodf['smb']\n",
    "hml = macrodf['hml']\n",
    "rmw = macrodf['rmw']\n",
    "cma = macrodf['cma']\n",
    "mom = macrodf['mom']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46qJHLbIBn1P"
   },
   "source": [
    "## Saving datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3VYcPFsMBceE",
    "outputId": "7371e77d-3113-4cb4-fa10-e7a32818c17d"
   },
   "outputs": [],
   "source": [
    "pickle.dump(df, open('data/df', 'wb'))\n",
    "\n",
    "pickle.dump(df_ml, open('data/df_ml', 'wb'))\n",
    "\n",
    "pickle.dump(df_mktvars, open('data/df_mktvars', 'wb'))\n",
    "\n",
    "pickle.dump([dates, dtdates, permnos, vrs, facs, returns, T, N, V, F], open('data/info', 'wb'))\n",
    "\n",
    "pickle.dump([rf, mkt_rf, smb, hml, rmw, cma, mom], open('data/misc', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "datacode.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
