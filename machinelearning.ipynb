{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QIwTcxqN78ne"
   },
   "source": [
    "# Algorithmic Market Efficiency - Machine Learning Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 29651,
     "status": "ok",
     "timestamp": 1582660322937,
     "user": {
      "displayName": "Constantin Schesch",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDzShDFJXhe-KA6VubV_vLoKhEeq2HWJUHqYaWV9A=s64",
      "userId": "12583853904578710112"
     },
     "user_tz": -60
    },
    "id": "Ga31qcQ478nh",
    "outputId": "aba42f1e-7277-40dd-c257-92fa6a6d5685"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.colors import LogNorm\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "filepath = 'output/'\n",
    "graphpath = 'graphs/'\n",
    "tablespath = 'tables/'\n",
    "\n",
    "print(\"current directory is : \" + os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YHidnp2s78nl"
   },
   "source": [
    "# Data importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zg2aGmhfrFfs"
   },
   "outputs": [],
   "source": [
    "df = pickle.load(open('data/df_ml', 'rb'))\n",
    "\n",
    "dates, dtdates, permnos, vrs, facs, returns, T, N, V, F =  pickle.load(open('data/info', 'rb'))\n",
    "\n",
    "predictions = pickle.load(open('mloutput/predictions', 'rb'))\n",
    "scores = pickle.load(open('mloutput/scores', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BWllTQPB78nx"
   },
   "source": [
    "# Data loading module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V9MHlrgJc3D8"
   },
   "outputs": [],
   "source": [
    "def yearlydataloader(curdates, prevdates):\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    print(\"*** Dataloader ***\")\n",
    "\n",
    "    if len(prevdates) == 0 : sys.exit()\n",
    "\n",
    "    # Current values\n",
    "    \n",
    "    curdf = df[df['date'].isin(curdates)]\n",
    "\n",
    "    curvalidpermnos = np.unique(np.array(curdf['permno']))\n",
    "\n",
    "    curvalidpmernomask = ~np.isnan(returns.loc[curdates])\n",
    "\n",
    "    curdf = curdf.set_index(['date', 'permno'])\n",
    "\n",
    "    curdf = curdf.stack(dropna=False).unstack(['date','permno'])\n",
    "\n",
    "    curdf = np.array(curdf).T\n",
    "\n",
    "    currets, curfacs = curdf[:,0], curdf[:,1:]\n",
    "    \n",
    "    # Treatment of nans: drop factors with >50% of nans, replace others by 0\n",
    "\n",
    "    curnanshares = [np.count_nonzero(np.isnan(curfacs[:,i])) / curfacs.shape[0] for i in range(curfacs.shape[1])]\n",
    "    curnanshares = np.array(curnanshares)\n",
    "    \n",
    "    curvalidfacs_idx = curnanshares<=0.5\n",
    "    curvalidfacs = facs[curvalidfacs_idx]\n",
    "\n",
    "    curfacs = curfacs[:, curvalidfacs_idx]\n",
    "    curfacs = np.nan_to_num(curfacs)\n",
    "\n",
    "    print(\"currets shape:\", currets.shape)\n",
    "    print(\"curfacs shape:\", curfacs.shape)\n",
    "\n",
    "    # Previous values\n",
    "    \n",
    "    prevdf = df[df['date'].isin(prevdates)]\n",
    "    prevdf = prevdf.fillna(0)\n",
    "\n",
    "    prevdf = prevdf.set_index(['date', 'permno'])\n",
    "    prevdf = prevdf.stack().unstack(['date','permno'])\n",
    "    prevdf = np.array(prevdf).T\n",
    "\n",
    "    prevrets = prevdf[:,0]\n",
    "    prevfacs = prevdf[:,1:]\n",
    "\n",
    "    # Treatment of nans: drop currently invalid factors, replace others by 0\n",
    "\n",
    "    prevfacs = prevfacs[:, curvalidfacs_idx]\n",
    "    prevfacs = np.nan_to_num(prevfacs)\n",
    "\n",
    "    # Train-test split for previous factors and returns:\n",
    "\n",
    "    prevfacs_train, prevfacs_test, prevrets_train, prevrets_test = train_test_split(prevfacs, prevrets, test_size=0.2, random_state=19111997)\n",
    "\n",
    "    print(\"prevrets_train shape:\", prevrets_train.shape)\n",
    "    print(\"prevrets_test shape:\", prevrets_test.shape)\n",
    "    \n",
    "    print(\"prevfacs_train shape:\", prevfacs_train.shape)\n",
    "    print(\"prevfacs_test shape:\", prevfacs_test.shape, \"\\n\")\n",
    "\n",
    "    return curfacs, currets, prevfacs_train, prevfacs_test, prevrets_train, prevrets_test, curvalidpermnos, curvalidfacs, curvalidpmernomask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VPRgPSny78n3"
   },
   "source": [
    "# Machine learning modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lJ2RWZE78n8"
   },
   "source": [
    "### OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2hvLpIJ78n9"
   },
   "outputs": [],
   "source": [
    "def ols(prevfacs_train, prevrets_train):\n",
    "                \n",
    "    ols_estimator = LinearRegression().fit(prevfacs_train, prevrets_train)\n",
    "    \n",
    "    return ols_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NdJArtWs78oB"
   },
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y38mtkC378oB"
   },
   "outputs": [],
   "source": [
    "def lasso(prevfacs_train, prevrets_train):\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    lasso_parameter = {'alpha':np.logspace(-10,10,100)}\n",
    "        \n",
    "    lasso_estimator = GridSearchCV(Lasso(), lasso_parameter, cv=3, return_train_score=True).fit(prevfacs_train, prevrets_train)\n",
    "    \n",
    "    paramvalues = lasso_estimator.cv_results_['param_alpha']    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.yscale('symlog')\n",
    "    plt.semilogx(paramvalues, lasso_estimator.cv_results_['split0_train_score'], 'r:')\n",
    "    plt.semilogx(paramvalues, lasso_estimator.cv_results_['split1_train_score'], 'r:')\n",
    "    plt.semilogx(paramvalues, lasso_estimator.cv_results_['split2_train_score'], 'r:')\n",
    "    plt.semilogx(paramvalues, lasso_estimator.cv_results_['mean_train_score'], 'r', label='train')\n",
    "    plt.semilogx(paramvalues, lasso_estimator.cv_results_['split0_test_score'], 'b:')\n",
    "    plt.semilogx(paramvalues, lasso_estimator.cv_results_['split1_test_score'], 'b:')\n",
    "    plt.semilogx(paramvalues, lasso_estimator.cv_results_['split2_test_score'], 'b:')\n",
    "    plt.semilogx(paramvalues, lasso_estimator.cv_results_['mean_test_score'], 'b', label='test')\n",
    "    plt.semilogx(paramvalues, np.zeros(len(paramvalues)), 'k--', linewidth=2)\n",
    "    plt.semilogx(paramvalues, np.ones(len(paramvalues)), 'k--', linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Lasso : alpha')\n",
    "    plt.title(\"Lasso Regression - 3-Fold Cross-Validation - \" + str(curdate))\n",
    "    plt.show()\n",
    "    \n",
    "    return lasso_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8w1zZeYL78oD"
   },
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1hu5MT478oD"
   },
   "outputs": [],
   "source": [
    "def ridge(prevfacs_train, prevrets_train):\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    ridge_parameter = {'alpha':np.logspace(-15,25,100)}\n",
    "        \n",
    "    ridge_estimator = GridSearchCV(Ridge(), ridge_parameter, cv=3, return_train_score=True).fit(prevfacs_train, prevrets_train)\n",
    "            \n",
    "    paramvalues = ridge_estimator.cv_results_['param_alpha']    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.yscale('symlog')\n",
    "    plt.semilogx(paramvalues, ridge_estimator.cv_results_['split0_train_score'], 'r:')\n",
    "    plt.semilogx(paramvalues, ridge_estimator.cv_results_['split1_train_score'], 'r:')\n",
    "    plt.semilogx(paramvalues, ridge_estimator.cv_results_['split2_train_score'], 'r:')\n",
    "    plt.semilogx(paramvalues, ridge_estimator.cv_results_['mean_train_score'], 'r', label='train')\n",
    "    plt.semilogx(paramvalues, ridge_estimator.cv_results_['split0_test_score'], 'b:')\n",
    "    plt.semilogx(paramvalues, ridge_estimator.cv_results_['split1_test_score'], 'b:')\n",
    "    plt.semilogx(paramvalues, ridge_estimator.cv_results_['split2_test_score'], 'b:')\n",
    "    plt.semilogx(paramvalues, ridge_estimator.cv_results_['mean_test_score'], 'b', label='test')\n",
    "    plt.semilogx(paramvalues, np.zeros(len(paramvalues)), 'k--', linewidth=2)\n",
    "    plt.semilogx(paramvalues, np.ones(len(paramvalues)), 'k--', linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Ridge : alpha')\n",
    "    plt.title(\"Ridge Regression - 3-Fold Cross-Validation - \" + str(curdate))\n",
    "    plt.show()\n",
    "    \n",
    "    return ridge_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rHSWYZLY78oG"
   },
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FVZEfqZn78oG"
   },
   "outputs": [],
   "source": [
    "def enet(prevfacs_train, prevrets_train):\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    alphas = np.logspace(-12,15,10)\n",
    "    l1_ratios = np.linspace(0,1,10)\n",
    "    enet_parameter = {'alpha':alphas, 'l1_ratio':l1_ratios}\n",
    "    \n",
    "    enet_estimator = GridSearchCV(ElasticNet(), enet_parameter, cv=3, return_train_score=True).fit(prevfacs_train, prevrets_train)\n",
    "    \n",
    "\n",
    "    scoresmatrix = np.reshape(enet_estimator.cv_results_['mean_test_score'], (len(alphas),len(l1_ratios)))    \n",
    "    paramvalues = enet_estimator.cv_results_['param_alpha']\n",
    "\n",
    "    plt.figure(figsize=(14,10))\n",
    "    plt.yscale('symlog')\n",
    "    for i, l1_ratio in enumerate(l1_ratios):\n",
    "        plt.semilogx(alphas, scoresmatrix[::, i], label='l1_ratio: ' + str(l1_ratios[i] % 0.01))\n",
    "    plt.semilogx(paramvalues, np.zeros(len(paramvalues)), 'k--', linewidth=2)\n",
    "    plt.semilogx(paramvalues, np.ones(len(paramvalues)), 'k--', linewidth=2)\n",
    "    plt.xlabel('Enet: alphas')\n",
    "    plt.ylabel('Mean test score')\n",
    "    plt.title(\"Elastic Net Regression - 3-Fold Cross-Validation - \" + str(curdate))\n",
    "    plt.show()\n",
    "    \n",
    "    return enet_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tIOFZ0Ok78oI"
   },
   "source": [
    "### Principal Components Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mW0-A7VK78oJ"
   },
   "outputs": [],
   "source": [
    "def pcr(prevfacs_train, prevrets_train):\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "                \n",
    "    olsfunction = LinearRegression()\n",
    "    pcafunction = PCA()\n",
    "    pipe = Pipeline(steps=[('pca', pcafunction), ('ols', olsfunction)])\n",
    "    \n",
    "    n_components = np.arange(1,25)\n",
    "    pcaparameter = {'pca__n_components': n_components}\n",
    "        \n",
    "    pcr_estimator = GridSearchCV(pipe, pcaparameter, cv=3, return_train_score=True).fit(prevfacs_train, prevrets_train)\n",
    "\n",
    "    \n",
    "    paramvalues = n_components\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.yscale('symlog')\n",
    "    plt.plot(paramvalues, pcr_estimator.cv_results_['split0_train_score'], 'r:')\n",
    "    plt.plot(paramvalues, pcr_estimator.cv_results_['split1_train_score'], 'r:')\n",
    "    plt.plot(paramvalues, pcr_estimator.cv_results_['split2_train_score'], 'r:')\n",
    "    plt.plot(paramvalues, pcr_estimator.cv_results_['mean_train_score'], 'r', label='train')\n",
    "    plt.plot(paramvalues, pcr_estimator.cv_results_['split0_test_score'], 'b:')\n",
    "    plt.plot(paramvalues, pcr_estimator.cv_results_['split1_test_score'], 'b:')\n",
    "    plt.plot(paramvalues, pcr_estimator.cv_results_['split2_test_score'], 'b:')\n",
    "    plt.plot(paramvalues, pcr_estimator.cv_results_['mean_test_score'], 'b', label='test')\n",
    "    plt.plot(paramvalues, np.zeros(len(paramvalues)), 'k--', linewidth=2)\n",
    "    plt.plot(paramvalues, np.ones(len(paramvalues)), 'k--', linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.xlabel('PCR : n_components')\n",
    "    plt.title(\"Principal Components Regression - 3-Fold Cross-Validation - \" + str(curdate))\n",
    "    plt.show()\n",
    "\n",
    "    return pcr_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w7-aZu6s78oL"
   },
   "source": [
    "### Partial Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zYxs3Yid78oL"
   },
   "outputs": [],
   "source": [
    "def pls(prevfacs_train, prevrets_train):\n",
    "        \n",
    "    # PLSRegression does not allow for 'get_params' so we have to code GridSearchCV manually\n",
    "    \n",
    "    trainscores = []\n",
    "    testscores = []\n",
    "    \n",
    "    splits = 3\n",
    "\n",
    "    for n in np.arange(1,25):\n",
    "\n",
    "            trainscore, testscore = 0, 0\n",
    "            \n",
    "            for train_index, test_index in KFold(n_splits=splits).split(prevfacs_train):\n",
    "\n",
    "                prevfacs_train_train, prevfacs_train_test = prevfacs_train[train_index], prevfacs_train[test_index]\n",
    "                prevrets_train_train, prevrets_train_test = prevrets_train[train_index], prevrets_train[test_index]\n",
    "                \n",
    "                pls_estimator = PLSRegression(n_components=n, scale=False).fit(prevfacs_train_train, prevrets_train_train)\n",
    "\n",
    "                trainscore += pls_estimator.score(prevfacs_train_train, prevrets_train_train)\n",
    "                testscore += pls_estimator.score(prevfacs_train_test, prevrets_train_test)\n",
    "                \n",
    "            trainscore = trainscore / splits\n",
    "            testscore = testscore / splits\n",
    "            \n",
    "            trainscores.append(trainscore)\n",
    "            testscores.append(testscore)\n",
    "    \n",
    "    nstar = np.argmin(testscores) + 1\n",
    "    \n",
    "    pls_estimator = PLSRegression(n_components=nstar, scale=False).fit(prevfacs_train, prevrets_train)\n",
    "    \n",
    "    \n",
    "    paramvalues = range(1,25)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.yscale('symlog')\n",
    "    plt.plot(paramvalues, trainscores, 'r', label='train, 5-cv')\n",
    "    plt.plot(paramvalues, testscores, 'b', label='test, 5-cv')\n",
    "    plt.plot(paramvalues, np.zeros(len(paramvalues)), 'k--', linewidth=2)\n",
    "    plt.plot(paramvalues, np.ones(len(paramvalues)), 'k--', linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.xlabel('PLS : n_components')\n",
    "    plt.title(\"Partial Least Squares Regression - 3-Fold Cross-Validation - \" + str(curdate))\n",
    "    plt.show()\n",
    "    \n",
    "    return pls_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "am8NWBJN78oP"
   },
   "source": [
    "### Regression tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AutuBpMS78oQ"
   },
   "outputs": [],
   "source": [
    "def tree(prevfacs_train, prevrets_train):\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    tree_estimator = DecisionTreeRegressor().fit(prevfacs_train, prevrets_train)\n",
    "    \n",
    "    return tree_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "am8NWBJN78oP"
   },
   "source": [
    "### Boosted tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AutuBpMS78oQ"
   },
   "outputs": [],
   "source": [
    "def gbrt(prevfacs_train, prevrets_train):\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    gbrt_estimator = GradientBoostingRegressor(warm_start=True).fit(prevfacs_train, prevrets_train)\n",
    "    \n",
    "    return gbrt_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "am8NWBJN78oP"
   },
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AutuBpMS78oQ"
   },
   "outputs": [],
   "source": [
    "def forest(prevfacs_train, prevrets_train):\n",
    "    \n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    forest_estimator = RandomForestRegressor().fit(prevfacs_train, prevrets_train)\n",
    "    \n",
    "    return forest_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PSBtpXTZrFgb"
   },
   "source": [
    "### 1-Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xyfR4eKorFgc"
   },
   "outputs": [],
   "source": [
    "def nn1(prevfacs_train, prevrets_train):\n",
    "                \n",
    "    nn1_parameter = {'hidden_layer_sizes': [(16), (32), (64)],\n",
    "              'activation': ['logistic'],\n",
    "              'learning_rate': ['invscaling'],\n",
    "              'power_t': [0.1, 0.5, 0.9],\n",
    "              'learning_rate_init': np.logspace(-4,0,5),\n",
    "              'max_iter': [250],\n",
    "              'warm_start': [True]}\n",
    "\n",
    "    nn1_estimator = GridSearchCV(MLPRegressor(), nn1_parameter, cv=2, return_train_score=True, n_jobs=-1).fit(prevfacs_train, prevrets_train)\n",
    "\n",
    "    testscores = nn1_estimator.cv_results_['mean_test_score']\n",
    "    trainscores = nn1_estimator.cv_results_['mean_train_score']\n",
    "    y_pos = np.arange(len(testscores))*3\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.yscale('symlog')\n",
    "    plt.bar(y_pos, trainscores, color='r', align='center',  label='train, 2-cv')\n",
    "    plt.bar(y_pos+1, testscores, color='b', align='center',  label='test, 2-cv')\n",
    "    plt.ylabel('mean_test_score')\n",
    "    plt.plot(y_pos, np.zeros(len(y_pos)), 'k--', linewidth=2)\n",
    "    plt.plot(y_pos, np.ones(len(y_pos)), 'k--', linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.title(\"1-Layer Neural Network - 2-Fold Cross-Validation - \" + str(curdate))\n",
    "    plt.show()\n",
    "\n",
    "    return nn1_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7W-6PdTzexeK"
   },
   "source": [
    "### 2-Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jrwmlS77eqtq"
   },
   "outputs": [],
   "source": [
    "def nn2(prevfacs_train, prevrets_train):\n",
    "                \n",
    "    nn2_parameter = {'hidden_layer_sizes': [(16,8), (32,16), (64,32)],\n",
    "              'activation': ['logistic'],\n",
    "              'learning_rate': ['invscaling'],\n",
    "              'power_t': [0.1, 0.5, 0.9],\n",
    "              'learning_rate_init': np.logspace(-4,0,5),\n",
    "              'max_iter': [250],\n",
    "              'warm_start': [True]}\n",
    "\n",
    "    nn2_estimator = GridSearchCV(MLPRegressor(), nn2_parameter, cv=2, return_train_score=True, verbose=1, n_jobs=-1).fit(prevfacs_train, prevrets_train)\n",
    "\n",
    "    testscores = nn2_estimator.cv_results_['mean_test_score']\n",
    "    trainscores = nn2_estimator.cv_results_['mean_train_score']\n",
    "    y_pos = np.arange(len(testscores))*3\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.yscale('symlog')\n",
    "    plt.bar(y_pos, trainscores, color='r', align='center',  label='train, 2-cv')\n",
    "    plt.bar(y_pos+1, testscores, color='b', align='center',  label='test, 2-cv')\n",
    "    plt.ylabel('mean_test_score')\n",
    "    plt.plot(y_pos, np.zeros(len(y_pos)), 'k--', linewidth=2)\n",
    "    plt.plot(y_pos, np.ones(len(y_pos)), 'k--', linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.title(\"2-Layer Neural Network - 2-Fold Cross-Validation - \" + str(curdate))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return nn2_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NFKFi0mSeqtp"
   },
   "source": [
    "### 3-Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "em3oXpofeqTR"
   },
   "outputs": [],
   "source": [
    "def nn3(prevfacs_train, prevrets_train):\n",
    "                \n",
    "    nn3_parameters = {'hidden_layer_sizes': [(16,8,4), (32,16,8), (64,32,16)],\n",
    "              'activation': ['logistic'],\n",
    "              'learning_rate': ['invscaling'],\n",
    "              'power_t': [0.1, 0.5, 0.9],\n",
    "              'learning_rate_init': np.logspace(-4,0,5),\n",
    "              'max_iter': [250],\n",
    "              'warm_start': [True]}\n",
    "\n",
    "    nn3_estimator = GridSearchCV(MLPRegressor(), nn3_parameters, cv=2, return_train_score=True, n_jobs=-1).fit(prevfacs_train, prevrets_train)\n",
    "\n",
    "    testscores = nn3_estimator.cv_results_['mean_test_score']\n",
    "    trainscores = nn3_estimator.cv_results_['mean_train_score']\n",
    "    \n",
    "    \n",
    "    y_pos = np.arange(len(testscores))*3\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.yscale('symlog')\n",
    "    plt.bar(y_pos, trainscores, color='r', align='center',  label='train, 2-cv')\n",
    "    plt.bar(y_pos+1, testscores, color='b', align='center',  label='test, 2-cv')\n",
    "    plt.ylabel('mean_test_score')\n",
    "    plt.plot(y_pos, np.zeros(len(y_pos)), 'k--', linewidth=2)\n",
    "    plt.plot(y_pos, np.ones(len(y_pos)), 'k--', linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.title(\"3-Layer Neural Network - 2-Fold Cross-Validation - \" + str(curdate))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return nn3_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3a5cX0BNs12k"
   },
   "source": [
    "### 5-Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAhmjK8FsxRz"
   },
   "outputs": [],
   "source": [
    "def nn5(prevfacs_train, prevrets_train):\n",
    "                \n",
    "    nn5_parameter = {'hidden_layer_sizes': [(64,32,16,8,4),(32,16,8,4,2)],\n",
    "                      'activation': ['relu'],\n",
    "                      'learning_rate': ['adaptive'],\n",
    "                      'learning_rate_init': [0.01],\n",
    "                      'max_iter': [1000],\n",
    "                      'warm_start': [True]}\n",
    "\n",
    "    nn5_estimator = GridSearchCV(MLPRegressor(), nn5_parameter, cv=2, return_train_score=True, n_jobs=-1).fit(prevfacs_train, prevrets_train)\n",
    "\n",
    "    testscores = nn5_estimator.cv_results_['mean_test_score']\n",
    "    trainscores = nn5_estimator.cv_results_['mean_train_score']\n",
    "    y_pos = np.arange(len(testscores))*3\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.yscale('symlog')\n",
    "    plt.bar(y_pos, trainscores, color='r', align='center',  label='train, 2-cv')\n",
    "    plt.bar(y_pos+1, testscores, color='b', align='center',  label='test, 2-cv')\n",
    "    plt.ylabel('mean_test_score')\n",
    "    plt.plot(y_pos, np.zeros(len(y_pos)), 'k--', linewidth=2)\n",
    "    plt.plot(y_pos, np.ones(len(y_pos)), 'k--', linewidth=2)\n",
    "    plt.legend()\n",
    "    plt.title(\"5-Layer Neural Network - 2-Fold Cross-Validation - \" + str(curdate))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return nn5_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3a5cX0BNs12k"
   },
   "source": [
    "### 10-Layer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAhmjK8FsxRz"
   },
   "outputs": [],
   "source": [
    "def nn10(prevfacs_train, prevrets_train):\n",
    "                \n",
    "    nn10_estimator = MLPRegressor(hidden_layer_sizes=(100, 90, 80, 70, 60, 50, 40, 30, 20, 10),\n",
    "                                    activation='relu',\n",
    "                                    learning_rate='adaptive',\n",
    "                                    learning_rate_init=0.01,\n",
    "                                    max_iter=1000,\n",
    "                                    warm_start=True).fit(prevfacs_train, prevrets_train)\n",
    "\n",
    "    return nn10_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "inLv3pBr78ox"
   },
   "source": [
    "# Core Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJLPs1MU78ox"
   },
   "outputs": [],
   "source": [
    "methods = ['ols', 'lasso', 'ridge', 'enet', 'pcr', 'pls', 'tree', 'gbrt', 'forest', 'nn1', 'nn2', 'nn3', 'nn5', 'nn10']\n",
    "M = len(methods)\n",
    "\n",
    "splits = ['train', 'test', 'oos']\n",
    "scoretypes = ['R2', 'spearman']\n",
    "\n",
    "if os.path.exists('mloutput/scores'):\n",
    "    scores = pickle.load(open('mloutput/scores', 'rb'))\n",
    "else:\n",
    "    scoreindex = pd.MultiIndex.from_product([dates, methods, splits, scoretypes], names=['date', 'method', 'split', 'scoretype'])\n",
    "    scores = pd.Series(np.nan, index=scoreindex)\n",
    "    pickle.dump(scores, open('mloutput/scores', 'wb'))\n",
    "    \n",
    "if os.path.exists('mloutput/predictions'):\n",
    "    predictions = pickle.load(open('mloutput/predictions', 'rb'))\n",
    "else:\n",
    "    predictions = returns.copy()\n",
    "    # We set unfilled predictions to exactly pi: this way we preserve the nan structure of the returns matrix,\n",
    "    # but can easily check whether in the end some values were not overwritten by actual predictitons.\n",
    "    predictions[~np.isnan(predictions)] = np.pi\n",
    "    predictions = dict(zip(methods,[predictions] * M))\n",
    "    pickle.dump(predictions, open('mloutput/predictions', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "rn1_6J6B78oz",
    "outputId": "92d706de-6ed8-4b82-cee5-791afd3af884"
   },
   "outputs": [],
   "source": [
    "runmethods = [ols]\n",
    "runmethodnames = [runmethod.__name__ for runmethod in runmethods]\n",
    "\n",
    "delta = 12*10\n",
    "override = False\n",
    "\n",
    "for t in range(12,T,12):\n",
    "    \n",
    "    print(\"*** New Loop ***\")\n",
    "    \n",
    "    curdate = dates[t]  \n",
    "    curdates = np.array(dates[t:t+12])\n",
    "    prevdates = np.array(dates[max(t-delta,0):t])\n",
    "    print(\"Out-of-sample dates:\", curdates)\n",
    "    print(\"Train/test dates:\", prevdates)\n",
    "\n",
    "    if np.isnan(scores.loc[(curdate,runmethodnames,'train','R2')]).any()==False and override==False:\n",
    "            print('All done!  Date : ', curdate, '\\n')\n",
    "            continue\n",
    "    \n",
    "    curfacs, currets, prevfacs_train, prevfacs_test, prevrets_train, prevrets_test, curvalidpermnos, curvalidfacs, curvalidpmernomask = yearlydataloader(curdates, prevdates)\n",
    "    \n",
    "    for method in runmethods:\n",
    "        \n",
    "        curmethod = method.__name__\n",
    "\n",
    "        print(\"*** Current method: \", curmethod, \" ***\")\n",
    "        \n",
    "        if np.isnan(scores.loc[(curdate,curmethod,'train','R2')]).any()==False and override==False:\n",
    "            print('Already done!  Date : ', curdate, '   Method : ', curmethod, '\\n')\n",
    "            continue\n",
    "        \n",
    "        estimator = method(prevfacs_train, prevrets_train)\n",
    "        \n",
    "\n",
    "        prediction_train = estimator.predict(prevfacs_train)\n",
    "        prediction_test = estimator.predict(prevfacs_test)\n",
    "        prediction = estimator.predict(curfacs)\n",
    "        \n",
    "        predictionscopy = predictions[curmethod].copy()\n",
    "\n",
    "        predictions_unmasked = predictionscopy.loc[curdates].to_numpy()\n",
    "        np.place(predictions_unmasked, curvalidpmernomask.values, prediction.flatten())\n",
    "\n",
    "        predictionscopy.loc[curdates] = predictions_unmasked\n",
    "        predictions[curmethod] = predictionscopy\n",
    "\n",
    "        # This part is very confusing, because .loc interacts weirdly with dictionnaries and overwrites them...\n",
    "        \n",
    "        scores.loc[(curdate,curmethod,'train','R2')] = r2_score(prevrets_train, prediction_train)\n",
    "        scores.loc[(curdate,curmethod,'train','spearman')] = sp.stats.spearmanr(prevrets_train, prediction_train)[0]\n",
    "\n",
    "        scores.loc[(curdate,curmethod,'test','R2')] = r2_score(prevrets_test, prediction_test)\n",
    "        scores.loc[(curdate,curmethod,'test','spearman')] = sp.stats.spearmanr(prevrets_test, prediction_test)[0]\n",
    "\n",
    "        scores.loc[(curdate,curmethod,'oos','R2')] = r2_score(currets, prediction)\n",
    "        scores.loc[(curdate,curmethod,'oos','spearman')] = sp.stats.spearmanr(currets, prediction)[0]\n",
    "\n",
    "        print(\"Train R2:\", scores.loc[(curdate,curmethod,'train','R2')])\n",
    "        print(\"Train spearman:\", scores.loc[(curdate,curmethod,'train','spearman')])\n",
    "        \n",
    "        print(\"Test R2:\", scores.loc[(curdate,curmethod,'test','R2')])\n",
    "        print(\"Test spearman:\", scores.loc[(curdate,curmethod,'test','spearman')])\n",
    "\n",
    "        print(\"Out-of-sample R2:\", scores.loc[(curdate,curmethod,'oos','R2')])\n",
    "        print(\"Out-of-sample Spearman:\", scores.loc[(curdate,curmethod,'oos','spearman')])\n",
    "\n",
    "        print('Great sucess!  Date : ', curdate, ' Method : ', curmethod, '\\n')\n",
    "\n",
    "        pickle.dump(predictions, open('mloutput/predictions', 'wb'))\n",
    "        pickle.dump(scores, open('mloutput/scores', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V9MHlrgJc3D8"
   },
   "outputs": [],
   "source": [
    "def dataloader2016(curdates, prevdates):\n",
    "            \n",
    "    curdf = df[df['date'].isin(curdates)]\n",
    "    curdf = curdf.set_index(['date', 'permno'])\n",
    "    \n",
    "    curdf = curdf.stack(dropna=False).unstack(['date','permno'])\n",
    "    curdf = np.array(curdf).T\n",
    "\n",
    "    currets = curdf[:,0]\n",
    "    curfacs = curdf[:,1:]\n",
    "\n",
    "    # Previous values\n",
    "    \n",
    "    prevdf = df[df['date'].isin(prevdates)]\n",
    "    prevdf = prevdf.fillna(0)\n",
    "\n",
    "    prevdf = prevdf.set_index(['date', 'permno'])\n",
    "    prevdf = prevdf.stack().unstack(['date','permno'])\n",
    "    prevdf = np.array(prevdf).T\n",
    "\n",
    "    prevrets = prevdf[:,0]\n",
    "    prevfacs = prevdf[:,1:]\n",
    "\n",
    "    # Train-test split for previous factors and returns:\n",
    "\n",
    "    prevfacs_train, prevfacs_test, prevrets_train, prevrets_test = train_test_split(prevfacs, prevrets, test_size=0.2, random_state=19111997)\n",
    "    \n",
    "    # Converting Nans to zeros\n",
    "    \n",
    "    prevfacs_train = np.nan_to_num(prevfacs_train)\n",
    "    prevfacs_test = np.nan_to_num(prevfacs_test)\n",
    "    curfacs = np.nan_to_num(curfacs)\n",
    "\n",
    "    return curfacs, currets, prevfacs_train, prevfacs_test, prevrets_train, prevrets_test\n",
    "\n",
    "t = len(dates) - 12\n",
    "curdate = dates[t]  \n",
    "curdates = np.array(dates[t:t+12])\n",
    "prevdates = np.array(dates[max(t-delta,0):t])\n",
    "\n",
    "curfacs, currets, prevfacs_train, prevfacs_test, prevrets_train, prevrets_test = dataloader2016(curdates, prevdates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmethods = [ols, lasso, ridge, enet, pcr, pls, tree, gbrt, forest, nn1, nn2, nn3, nn5, nn10]\n",
    "testmethodnames = [testmethod.__name__ for testmethod in testmethods]\n",
    "testmethodlabels = ['OLS', 'Lasso', 'Ridge', 'Enet', 'PCR', 'PLS', 'Tree', 'GBRT', 'Forest', 'NN1', 'NN2', 'NN3', 'NN5', 'NN10']\n",
    "\n",
    "if os.path.exists('mloutput/estimators2016/full/estimatorsdict'):\n",
    "    estimatorsdict = pickle.load(open('mloutput/estimators2016/full/estimatorsdict', 'rb'))\n",
    "else: estimatorsdict = dict()\n",
    "\n",
    "for method in testmethods:\n",
    "    \n",
    "    methodname = method.__name__\n",
    "\n",
    "    print(\"*** Current method: \", methodname, \" ***\")\n",
    "    \n",
    "    if methodname in estimatorsdict:\n",
    "        print(\"Already done!\")\n",
    "        continue\n",
    "\n",
    "    estimator = method(prevfacs_train, prevrets_train)\n",
    "\n",
    "    estimatorsdict[methodname] = estimator\n",
    "    \n",
    "    pickle.dump(estimatorsdict, open('mloutput/estimators2016/full/estimatorsdict', 'wb'))\n",
    "    \n",
    "    print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('mloutput/estimators2016/full/partspearmans'):\n",
    "    \n",
    "    basescores_train, basescores_test, basescores_oos = pickle.load(open('mloutput/estimators2016/full/basescores', 'rb'))\n",
    "    partscores_train, partscores_test, partscores_oos = pickle.load(open('mloutput/estimators2016/full/partscores', 'rb'))\n",
    "    \n",
    "    basespearmans_train, basespearmans_test, basespearmans_oos = pickle.load(open('mloutput/estimators2016/full/basespearmans', 'rb'))\n",
    "    partspearmans_train, partspearmans_test, partspearmans_oos = pickle.load(open('mloutput/estimators2016/full/partspearmans', 'rb'))\n",
    "    \n",
    "else:\n",
    "    \n",
    "    basescores_train = np.full(len(testmethods), np.nan)\n",
    "    partscores_train = np.full([F, len(testmethods)], np.nan)\n",
    "    basescores_test = np.full(len(testmethods), np.nan)\n",
    "    partscores_test = np.full([F, len(testmethods)], np.nan)\n",
    "    basescores_oos = np.full(len(testmethods), np.nan)\n",
    "    partscores_oos = np.full([F, len(testmethods)], np.nan)\n",
    "    \n",
    "    basespearmans_train = np.full(len(testmethods), np.nan)\n",
    "    partspearmans_train = np.full([F, len(testmethods)], np.nan)\n",
    "    basespearmans_test = np.full(len(testmethods), np.nan)\n",
    "    partspearmans_test = np.full([F, len(testmethods)], np.nan)\n",
    "    basespearmans_oos = np.full(len(testmethods), np.nan)\n",
    "    partspearmans_oos = np.full([F, len(testmethods)], np.nan)\n",
    "\n",
    "for i, method in enumerate(testmethods):\n",
    "    \n",
    "    continue\n",
    "            \n",
    "    methodname = method.__name__\n",
    "    estimator = estimatorsdict[methodname]\n",
    "    \n",
    "    prediction_train = estimator.predict(prevfacs_train)\n",
    "    prediction_test = estimator.predict(prevfacs_test)\n",
    "    prediction_oos = estimator.predict(curfacs)\n",
    "    \n",
    "    basescores_train[i] = r2_score(prevrets_train, prediction_train)\n",
    "    basescores_test[i] = r2_score(prevrets_test, prediction_test)\n",
    "    basescores_oos[i] = r2_score(currets, prediction_oos)\n",
    "    \n",
    "    basespearmans_train[i] = sp.stats.spearmanr(prevrets_train, prediction_train)[0]\n",
    "    basespearmans_test[i] = sp.stats.spearmanr(prevrets_test, prediction_test)[0]\n",
    "    basespearmans_oos[i] = sp.stats.spearmanr(currets, prediction_oos)[0]\n",
    "        \n",
    "    for j in range(F):\n",
    "        \n",
    "        if (j%25)==0: print('Method:', methodname, 'Factor:', j+1, 'out of', F)\n",
    "                                      \n",
    "        prevfacs_train_factorsettozero = prevfacs_train.copy()\n",
    "        prevfacs_train_factorsettozero[:,j] = 0\n",
    "        \n",
    "        prevfacs_test_factorsettozero = prevfacs_test.copy()\n",
    "        prevfacs_test_factorsettozero[:,j] = 0\n",
    "        \n",
    "        curfacs_factorsettozero = curfacs.copy()\n",
    "        curfacs_factorsettozero[:,j] = 0\n",
    "        \n",
    "        prediction_train_factorsettozero = estimator.predict(prevfacs_train_factorsettozero)           \n",
    "        partscores_train[j,i] = r2_score(prevrets_train, prediction_train_factorsettozero)\n",
    "        partspearmans_train[j,i] = sp.stats.spearmanr(prevrets_train, prediction_train_factorsettozero)[0]\n",
    "\n",
    "        prediction_test_factorsettozero = estimator.predict(prevfacs_test_factorsettozero)           \n",
    "        partscores_test[j,i] = r2_score(prevrets_test, prediction_test_factorsettozero)\n",
    "        partspearmans_test[j,i] = sp.stats.spearmanr(prevrets_test, prediction_test_factorsettozero)[0]\n",
    "        \n",
    "        prediction_oos_factorsettozero = estimator.predict(curfacs_factorsettozero)           \n",
    "        partscores_oos[j,i] = r2_score(currets, prediction_oos_factorsettozero)\n",
    "        partspearmans_oos[j,i] = sp.stats.spearmanr(currets, prediction_oos_factorsettozero)[0]\n",
    "        \n",
    "    pickle.dump([basescores_train, basescores_test, basescores_oos], open('mloutput/estimators2016/full/basescores', 'wb'))\n",
    "    pickle.dump([partscores_train, partscores_test, partscores_oos], open('mloutput/estimators2016/full/partscores', 'wb'))\n",
    "    \n",
    "    pickle.dump([basespearmans_train, basespearmans_test, basespearmans_oos], open('mloutput/estimators2016/full/basespearmans', 'wb'))\n",
    "    pickle.dump([partspearmans_train, partspearmans_test, partspearmans_oos], open('mloutput/estimators2016/full/partspearmans', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorimportancetable(split, scoretype):\n",
    "\n",
    "    m = len(testmethodlabels)\n",
    "    \n",
    "    if scoretype=='R2':\n",
    "        if split=='train': partscores, basescores = partscores_train, basescores_train\n",
    "        elif split=='test': partscores, basescores = partscores_test, basescores_test\n",
    "        elif split=='oos': partscores, basescores = partscores_oos, basescores_oos\n",
    "    elif scoretype=='spearman':\n",
    "        if split=='train': partscores, basescores = partspearmans_train, basespearmans_train\n",
    "        elif split=='test': partscores, basescores = partspearmans_test, basespearmans_test\n",
    "        elif split=='oos': partscores, basescores = partspearmans_oos, basespearmans_oos\n",
    "\n",
    "\n",
    "    matrix = - (partscores - basescores) / basescores\n",
    "    matrix[matrix<0.00001] = 0.00001\n",
    "    matrix[matrix>1] = 1\n",
    "\n",
    "    matrix = matrix / np.nansum(matrix, axis=0)\n",
    "\n",
    "    sumbyfac = np.nansum(matrix, axis=1)\n",
    "    sortidxs = sumbyfac.argsort()\n",
    "    \n",
    "    matrix = matrix[sortidxs[::-1],:]\n",
    "    facs_sorted = facs[sortidxs[::-1]]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (11,14))\n",
    "    im = ax.imshow(matrix, aspect= \"auto\", cmap=\"Purples\", norm=LogNorm(vmin=0.00001, vmax=1))\n",
    "    \n",
    "    ax.set_xticks(np.arange(len(testmethodlabels)))\n",
    "    ax.set_yticks(np.arange(len(facs)))\n",
    "\n",
    "    ax.set_xticklabels(testmethodlabels, size=12)\n",
    "    ax.set_yticklabels(facs_sorted, size=8)\n",
    "\n",
    "    ax.tick_params(top=True, bottom=False, labeltop=True, labelbottom=False)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(matrix.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(matrix.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=1.5)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "    ax.tick_params(which=\"major\", top=False, left=False)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.savefig(graphpath+'factorimportancetable_'+split+'_'+scoretype+'.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "factorimportancetable('train', 'R2')\n",
    "factorimportancetable('train', 'spearman')\n",
    "\n",
    "factorimportancetable('test', 'R2')\n",
    "factorimportancetable('test', 'spearman')\n",
    "\n",
    "factorimportancetable('oos', 'R2')\n",
    "factorimportancetable('oos', 'spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transposed version for the slides:\n",
    "\n",
    "def factorimportancetable(split, scoretype):\n",
    "\n",
    "    m = len(testmethodlabels)\n",
    "    \n",
    "    if scoretype=='R2':\n",
    "        if split=='train': partscores, basescores = partscores_train, basescores_train\n",
    "        elif split=='test': partscores, basescores = partscores_test, basescores_test\n",
    "        elif split=='oos': partscores, basescores = partscores_oos, basescores_oos\n",
    "    elif scoretype=='spearman':\n",
    "        if split=='train': partscores, basescores = partspearmans_train, basespearmans_train\n",
    "        elif split=='test': partscores, basescores = partspearmans_test, basespearmans_test\n",
    "        elif split=='oos': partscores, basescores = partspearmans_oos, basespearmans_oos\n",
    "\n",
    "\n",
    "    matrix = - (partscores - basescores) / basescores\n",
    "    matrix[matrix<0.00001] = 0.00001\n",
    "    matrix[matrix>1] = 1\n",
    "\n",
    "    matrix = matrix / np.nansum(matrix, axis=0)\n",
    "\n",
    "    sumbyfac = np.nansum(matrix, axis=1)\n",
    "    sortidxs = sumbyfac.argsort()\n",
    "    \n",
    "    matrix = matrix[sortidxs[::-1],:]\n",
    "    facs_sorted = facs[sortidxs[::-1]]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (14,7))\n",
    "    im = ax.imshow(matrix.T, aspect= \"auto\", cmap=\"Purples\", norm=LogNorm(vmin=0.00001, vmax=1))\n",
    "    \n",
    "    ax.set_yticks(np.arange(len(testmethodlabels)))\n",
    "    ax.set_xticks(np.arange(len(facs)))\n",
    "\n",
    "    ax.set_yticklabels(testmethodlabels, size=12)\n",
    "    ax.set_xticklabels(facs_sorted, size=8)\n",
    "\n",
    "    ax.tick_params(top=True, bottom=False, labeltop=True, labelbottom=False)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"left\", rotation_mode=\"anchor\")\n",
    "\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(matrix.T.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(matrix.T.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=1.5)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "    ax.tick_params(which=\"major\", top=False, left=False)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.savefig(graphpath+'factorimportancetable_transpose_'+split+'_'+scoretype+'.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "factorimportancetable('train', 'R2')\n",
    "factorimportancetable('oos', 'R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palettecycle = sns.color_palette('muted', 4)\n",
    "\n",
    "keyfacs = ['beta', 'mvel1', 'bm', 'mom6m']    \n",
    "keyfaclabels = ['Beta', 'Log Market Equity ', 'Book-to-market', '6-Month Momentum']    \n",
    "keyfaclabels2 = ['Beta', 'Log Market\\n Equity ', 'Book-to-market', '6-Month \\n Momentum']    \n",
    "\n",
    "def predictoranalysisplot(estimator, estimatorname, estimatorlabel, titlestr):\n",
    "    \n",
    "    pts = 100\n",
    "\n",
    "    fig, ax = plt.subplots(len(keyfacs), len(keyfacs), figsize=(14,14*0.65))\n",
    "    \n",
    "    for axis in ax.flatten():\n",
    "        axis.spines['right'].set_visible(False)\n",
    "        axis.spines['top'].set_visible(False)\n",
    "\n",
    "    for (y, facy) in enumerate(keyfacs):\n",
    "\n",
    "        facyidx = list(facs).index(facy)\n",
    "                \n",
    "        for (x, facx) in enumerate(keyfacs):\n",
    "\n",
    "            facxidx = list(facs).index(facx)\n",
    "            \n",
    "            xm2 = np.zeros((pts, F))\n",
    "            xm1 = np.zeros((pts, F))\n",
    "            x0 = np.zeros((pts, F))\n",
    "            xp1 = np.zeros((pts, F))\n",
    "            xp2 = np.zeros((pts, F))\n",
    "\n",
    "            stdspace = np.linspace(-2.1, 2.1, pts)\n",
    "            \n",
    "            xm2[:,facxidx] = stdspace.copy()\n",
    "            xm1[:,facxidx] = stdspace.copy()\n",
    "            x0[:,facxidx] = stdspace.copy()\n",
    "            xp1[:,facxidx] = stdspace.copy()\n",
    "            xp2[:,facxidx] = stdspace.copy()\n",
    "            \n",
    "            xm2[:,facyidx] = -2\n",
    "            xm1[:,facyidx] = -1\n",
    "            x0[:,facyidx] = 0\n",
    "            xp1[:,facyidx] = 1\n",
    "            xp2[:,facyidx] = 2\n",
    "            \n",
    "            predictedreturnsm2 = estimator.predict(xm2)\n",
    "            predictedreturnsm1 = estimator.predict(xm1)\n",
    "            predictedreturns0 = estimator.predict(x0)\n",
    "            predictedreturnsp1 = estimator.predict(xp1)\n",
    "            predictedreturnsp2 = estimator.predict(xp2)\n",
    "            \n",
    "            if x==y:\n",
    "                \n",
    "                x0[:,facxidx] = stdspace.copy()\n",
    "                predictedreturns0 = estimator.predict(x0)\n",
    "                \n",
    "                predictedreturnsm2 = predictedreturns0\n",
    "                predictedreturnsm1 = predictedreturns0\n",
    "                predictedreturnsp1 = predictedreturns0\n",
    "                predictedreturnsp2 = predictedreturns0\n",
    "            \n",
    "            \n",
    "            colors = sns.light_palette(palettecycle[y], reverse=True)\n",
    "            \n",
    "            ax[y, x].plot(stdspace, predictedreturnsm2, c=colors[0], label='- 2 std')\n",
    "            ax[y, x].plot(stdspace, predictedreturnsm1, c=colors[1], label='- 1 std')\n",
    "            ax[y, x].plot(stdspace, predictedreturns0, c=colors[2], label='   avg')\n",
    "            ax[y, x].plot(stdspace, predictedreturnsp1, c=colors[3], label='+1 std')\n",
    "            ax[y, x].plot(stdspace, predictedreturnsp2, c=colors[4], label='+2 std')\n",
    "            ax[y, x].plot(stdspace, predictedreturns0, c=colors[2])\n",
    "\n",
    "            ax[y, x].set_xlabel(facs[facxidx] + ' (stds)')\n",
    "            ax[y, x].set_ylabel('return')\n",
    "            ax[y, x].tick_params(axis='both', which='major', labelsize=8)\n",
    "            ax[y, x].xaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "            ax[y, x].yaxis.set_major_locator(plt.MaxNLocator(3))\n",
    "            ax[y, x].yaxis.set_major_formatter(mtick.PercentFormatter(xmax=1.0, decimals=1, symbol=None))\n",
    "            \n",
    "            if y==0:\n",
    "                ax[y, x].set_title(keyfaclabels[x], y=1.2, fontsize=11)\n",
    "            \n",
    "            if x==0:\n",
    "                l = ax[y, x].legend(frameon=False, title=keyfaclabels2[y], bbox_to_anchor=(-0.3,0.5), loc=\"center right\")\n",
    "                plt.setp(l.get_title(), multialignment='center', fontsize=11)\n",
    "                l._legend_box.sep = 10\n",
    "    \n",
    "    plt.suptitle(titlestr, y=1.03, fontsize=13)\n",
    "    fig.tight_layout(pad=1.0)\n",
    "    plt.savefig(graphpath+'predictoranalysisplot_'+estimatorname+'.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "predictoranalysisplot(estimatorsdict['ols'], 'ols', 'OLS', 'OLS Estimator Trained over 2005-2015')\n",
    "predictoranalysisplot(estimatorsdict['pcr'], 'pcr', 'PCR', 'PCR Estimator Trained over 2005-2015')\n",
    "predictoranalysisplot(estimatorsdict['tree'], 'tree', 'Tree', 'Regression Tree Trained over 2005-2015')\n",
    "predictoranalysisplot(estimatorsdict['gbrt'], 'gbrt', 'GBRT', 'Gradient-Boosted Regression Tree Trained over 2005-2015')\n",
    "predictoranalysisplot(estimatorsdict['forest'], 'forest', 'Forest', 'Random Forest Trained over 2005-2015')\n",
    "predictoranalysisplot(estimatorsdict['nn1'], 'nn1', 'NN1', '1-Layer Neural Network Estimator Trained over 2005-2015')\n",
    "predictoranalysisplot(estimatorsdict['nn2'], 'nn2', 'NN2', '2-Layer Neural Network Trained over 2005-2015')\n",
    "predictoranalysisplot(estimatorsdict['nn3'], 'nn3', 'NN3', '3-Layer Neural Network Trained over 2005-2015')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of ML algorithms on (random) subsets of factors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(19111997)\n",
    "\n",
    "facidxlists_10p = dict()\n",
    "for i in range(10): facidxlists_10p[i] = np.random.randint(0, F, int(F*(10/100)))\n",
    "\n",
    "facidxlists_25p = dict()\n",
    "for i in range(10): facidxlists_25p[i] = np.random.randint(0, F, int(F*(25/100)))\n",
    "\n",
    "facidxlists_50p = dict()\n",
    "for i in range(10): facidxlists_50p[i] = np.random.randint(0, F, int(F*(50/100)))\n",
    "\n",
    "facidxlists_75p = dict()\n",
    "for i in range(10): facidxlists_75p[i] = np.random.randint(0, F, int(F*(75/100)))\n",
    "\n",
    "facidxlists_90p = dict()\n",
    "for i in range(10): facidxlists_90p[i] = np.random.randint(0, F, int(F*(90/100)))\n",
    "\n",
    "\n",
    "subsettestmethods = [ols, pcr, tree, forest, nn1, nn2, nn3]\n",
    "subsettestmethodnames = ['ols', 'pcr', 'tree', 'forest', 'nn1', 'nn2', 'nn3']\n",
    "subsettestmethodlabels = ['OLS', 'PCR', 'Tree', 'Forest', 'NN1', 'NN2', 'NN3']\n",
    "subsettestmethodcolors = plt.rcParams['axes.prop_cycle'].by_key()['color'][:len(subsettestmethods)]\n",
    "\n",
    "samples = ['train', 'test', 'oos']\n",
    "scoretypes = ['R2', 'spearman']\n",
    "subsets = ['10%', '25%', '50%', '75%', '90%']\n",
    "splits = np.arange(10)\n",
    "\n",
    "if not os.path.exists('mloutput/estimators2016/subsetscores'):\n",
    "    subsetscoreindex = pd.MultiIndex.from_product([subsettestmethodnames, samples, scoretypes, subsets, splits], names=['method', 'sample', 'scoretype', 'subset', 'split'])\n",
    "    subsetscores = pd.Series(np.nan, index=subsetscoreindex)\n",
    "    print('Redefining!')\n",
    "else:\n",
    "    subsetscores = pickle.load(open('mloutput/estimators2016/subsetscores', 'rb'))\n",
    "    print('Using loaded scores!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in subsets:\n",
    "\n",
    "    for (i, splitnumber) in enumerate(range(10)):\n",
    "        \n",
    "        if subset == '10%': splitfacidxs = facidxlists_10p[splitnumber]\n",
    "        elif subset == '25%': splitfacidxs = facidxlists_25p[splitnumber]\n",
    "        elif subset == '50%': splitfacidxs = facidxlists_50p[splitnumber]\n",
    "        elif subset == '75%': splitfacidxs = facidxlists_75p[splitnumber]\n",
    "        elif subset == '90%': splitfacidxs = facidxlists_90p[splitnumber]\n",
    "        elif subset == '100%':\n",
    "            splitfacidxs = np.arange(len(facs))\n",
    "            if i!=0: continue\n",
    "\n",
    "        for method in subsettestmethods:\n",
    "            \n",
    "            methodname = method.__name__\n",
    "            \n",
    "            if (methodname == 'pcr') & (subset == '10%') : continue\n",
    "            if (methodname == 'pls') & (subset == '10%') : continue\n",
    "            \n",
    "            if os.path.exists('mloutput/estimators2016/' + subset + '/estimator_split' + str(splitnumber) + '_' + methodname):\n",
    "                estimator = pickle.load(open('mloutput/estimators2016/' + subset + '/estimator_split' + str(splitnumber) + '_' + methodname, 'rb'))\n",
    "                print(\"Current subset:\", subset, \"Current split :\", splitnumber, \"Current method: \", methodname, '-> Already estimated!')\n",
    "                continue\n",
    "            else:\n",
    "                print(\"Current subset:\", subset, \"Current split :\", splitnumber, \"Current method: \", methodname, '-> To do!')\n",
    "                estimator = method(prevfacs_train[:,splitfacidxs], prevrets_train)\n",
    "\n",
    "            prediction_train = estimator.predict(prevfacs_train[:,splitfacidxs])\n",
    "            subsetscores.loc[(methodname,'train','R2', subset, splitnumber)] = r2_score(prevrets_train, prediction_train)\n",
    "            subsetscores.loc[(methodname,'train','spearman', subset, splitnumber)] = sp.stats.spearmanr(prevrets_train, prediction_train)[0]\n",
    "\n",
    "            prediction_test = estimator.predict(prevfacs_test[:,splitfacidxs])\n",
    "            subsetscores.loc[(methodname,'test','R2', subset, splitnumber)] = r2_score(prevrets_test, prediction_test)\n",
    "            subsetscores.loc[(methodname,'test','spearman', subset, splitnumber)] = sp.stats.spearmanr(prevrets_test, prediction_test)[0]\n",
    "\n",
    "            prediction_oos = estimator.predict(curfacs[:,splitfacidxs])\n",
    "            subsetscores.loc[(methodname,'oos','R2', subset, splitnumber)] = r2_score(currets, prediction_oos)\n",
    "            subsetscores.loc[(methodname,'oos','spearman', subset, splitnumber)] = sp.stats.spearmanr(currets, prediction_oos)[0]\n",
    "\n",
    "            pickle.dump(estimator, open('mloutput/estimators2016/' + subset + '/estimator_split' + str(splitnumber) + '_' + methodname, 'wb'))\n",
    "            pickle.dump(subsetscores, open('mloutput/estimators2016/subsetscores', 'wb'))\n",
    "            pickle.dump(subsetscores, open('mloutput/estimators2016/subsetscores2', 'wb'))\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetscores_splitavgs = subsetscores.groupby(['method', 'sample', 'scoretype', 'subset']).mean()\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(0.75*20, 20))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for axis in ax:\n",
    "    axis.spines['right'].set_visible(False)\n",
    "    axis.spines['top'].set_visible(False)\n",
    "        \n",
    "    for tk in axis.get_yticklabels():\n",
    "        tk.set_visible(True)\n",
    "    \n",
    "def scores_scatter(ax, split, scoretype, titlestr):\n",
    "    \n",
    "    s = subsetscores_splitavgs.loc[:,split,scoretype]\n",
    "\n",
    "    for (i, methodname) in enumerate(subsettestmethodnames):\n",
    "\n",
    "        ax.plot(subsets, s.loc[methodname].values, subsettestmethodcolors[i], marker='o', linestyle='', markersize=6, label=subsettestmethodlabels[i])\n",
    "        ax.plot('100%', scores.loc[20160129, methodname, split, scoretype], subsettestmethodcolors[i], marker='o', markersize=6)\n",
    "  \n",
    "    ols_labels = np.concatenate((subsets, ['100%']))\n",
    "    ols_scores = np.concatenate((s.loc['ols'].values, [scores.loc[20160129, 'ols', split, scoretype]]))\n",
    "    ax.plot(ols_labels, ols_scores, 'C0--')\n",
    "\n",
    "    ax.set_title(titlestr)\n",
    "    ax.set_xlabel('Percentage of sampled factors')\n",
    "    ax.set_ylabel('Average score across 10 splits')    \n",
    "    ax.legend(frameon=False)\n",
    "\n",
    "\n",
    "scores_scatter(ax[0], 'train', 'R2', 'Train R2')\n",
    "scores_scatter(ax[1], 'train', 'spearman', 'Train Spearman')\n",
    "scores_scatter(ax[2], 'test', 'R2', 'Test R2')\n",
    "scores_scatter(ax[3], 'test', 'spearman', 'Test Spearman')\n",
    "scores_scatter(ax[4], 'oos', 'R2', 'Out-of-sample R2')\n",
    "scores_scatter(ax[5], 'oos', 'spearman', 'Out-of-sample Spearman')\n",
    "\n",
    "ax[0].set_ylim([-0.02, 1.02])\n",
    "ax[1].set_ylim([-0.02, 1.02])\n",
    "\n",
    "ax[2].set_ylim([-0.02, 0.75])\n",
    "ax[3].set_ylim([-0.02, 0.75])\n",
    "\n",
    "ax[4].set_ylim([-0.02, 0.75])\n",
    "ax[5].set_ylim([-0.02, 0.75])\n",
    "\n",
    "plt.savefig(graphpath+'subsamplescores.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transposed version for the slides\n",
    "\n",
    "subsetscores_splitavgs = subsetscores.groupby(['method', 'sample', 'scoretype', 'subset']).mean()\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(16, 10))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for axis in ax:\n",
    "    axis.spines['right'].set_visible(False)\n",
    "    axis.spines['top'].set_visible(False)\n",
    "        \n",
    "    for tk in axis.get_yticklabels():\n",
    "        tk.set_visible(True)\n",
    "    \n",
    "def scores_scatter(ax, split, scoretype, titlestr):\n",
    "    \n",
    "    s = subsetscores_splitavgs.loc[:,split,scoretype]\n",
    "\n",
    "    for (i, methodname) in enumerate(subsettestmethodnames):\n",
    "\n",
    "        ax.plot(subsets, s.loc[methodname].values, subsettestmethodcolors[i], marker='o', linestyle='', markersize=6, label=subsettestmethodlabels[i])\n",
    "        ax.plot('100%', scores.loc[20160129, methodname, split, scoretype], subsettestmethodcolors[i], marker='o', markersize=6)\n",
    "  \n",
    "    ols_labels = np.concatenate((subsets, ['100%']))\n",
    "    ols_scores = np.concatenate((s.loc['ols'].values, [scores.loc[20160129, 'ols', split, scoretype]]))\n",
    "    ax.plot(ols_labels, ols_scores, 'C0--')\n",
    "\n",
    "    ax.set_title(titlestr)\n",
    "    ax.set_xlabel('Percentage of sampled factors')\n",
    "    ax.set_ylabel('Average score across 10 splits')\n",
    "    \n",
    "    if not (titlestr=='Train Spearman' or titlestr=='Train R2'): ax.legend(frameon=False)\n",
    "\n",
    "\n",
    "scores_scatter(ax[0], 'train', 'R2', 'Train R2')\n",
    "scores_scatter(ax[1], 'test', 'R2', 'Test R2')\n",
    "scores_scatter(ax[2], 'oos', 'R2', 'Out-of-sample R2')\n",
    "scores_scatter(ax[3], 'train', 'spearman', 'Train Spearman')\n",
    "scores_scatter(ax[4], 'test', 'spearman', 'Test Spearman')\n",
    "scores_scatter(ax[5], 'oos', 'spearman', 'Out-of-sample Spearman')\n",
    "\n",
    "ax[0].set_ylim([-0.02, 1.02])\n",
    "ax[3].set_ylim([-0.02, 1.02])\n",
    "\n",
    "ax[1].set_ylim([-0.02, 0.75])\n",
    "ax[4].set_ylim([-0.02, 0.75])\n",
    "\n",
    "ax[2].set_ylim([-0.02, 0.75])\n",
    "ax[5].set_ylim([-0.02, 0.75])\n",
    "\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.savefig(graphpath+'subsamplescores_transposed.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "code.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
